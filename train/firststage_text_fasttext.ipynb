{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using fast-text to process text data classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xgboost as xgb\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import keras.preprocessing.text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import keras\n",
    "# from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, SpatialDropout1D, Embedding, LSTM\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fastText'...\n",
      "remote: Enumerating objects: 3854, done.\u001b[K\n",
      "remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\u001b[K\n",
      "Receiving objects: 100% (3854/3854), 8.22 MiB | 15.89 MiB/s, done.\n",
      "Resolving deltas: 100% (2417/2417), done.\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/args.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/autotune.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/matrix.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/dictionary.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/loss.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/productquantizer.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/densematrix.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/quantmatrix.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/vector.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/model.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/utils.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/meter.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/fasttext.cc\n",
      "c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG args.o autotune.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n"
     ]
    }
   ],
   "source": [
    "# download fasttext\n",
    "! git clone https://github.com/facebookresearch/fastText.git\n",
    "! cd /kaggle/working/fastText; make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/uw-cs480-fall20/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/uw-cs480-fall20/test.csv\")\n",
    "\n",
    "data = pd.DataFrame(pd.concat([train, test]))\n",
    "\n",
    "# text processing\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "\n",
    "train['TextDescription'] = train['noisyTextDescription'].apply(clean_text)\n",
    "train['TextDescription'] = train['TextDescription'].str.replace('\\d+', '')\n",
    "\n",
    "test['TextDescription'] = test['noisyTextDescription'].apply(clean_text)\n",
    "test['TextDescription'] = test['TextDescription'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text processing to the fast-text format\n",
    "\n",
    "train[\"label\"] = \"__label__\" + train[\"category\"].str.replace(\" \", \"_\")\n",
    "train_fast = pd.DataFrame(train, columns = [\"label\", \"TextDescription\"])\n",
    "train_fast.to_csv(r'train_fast.txt', index=False, sep=' ', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the train and val data (5-fold)\n",
    "\n",
    "val_size = int(len(train)/5)\n",
    "\n",
    "train1 = train_fast[val_size:]\n",
    "train1.to_csv(\"train1.txt\",sep=' ',index = None, header=None)\n",
    "val1 = train_fast[:val_size]\n",
    "val1.to_csv(\"val1.txt\",sep=' ',index = None, header=None)\n",
    "\n",
    "train2 = pd.concat([train_fast.iloc[:val_size,], train_fast.iloc[val_size*2:]])\n",
    "train2.to_csv(\"train2.txt\",sep=' ',index = None, header=None)\n",
    "val2 = train_fast[val_size:val_size*2]\n",
    "val2.to_csv(\"val2.txt\",sep=' ',index = None, header=None)\n",
    "\n",
    "train3 = pd.concat([train_fast.iloc[:val_size*2,], train_fast.iloc[val_size*3:]])\n",
    "train3.to_csv(\"train3.txt\",sep=' ',index = None, header=None)\n",
    "val3 = train_fast[val_size*2:val_size*3]\n",
    "val3.to_csv(\"val3.txt\",sep=' ',index = None, header=None)\n",
    "\n",
    "train4 = pd.concat([train_fast.iloc[:val_size*3,], train_fast.iloc[val_size*4:]])\n",
    "train4.to_csv(\"train4.txt\",sep=' ',index = None, header=None)\n",
    "val4 = train_fast[val_size*3:val_size*4]\n",
    "val4.to_csv(\"val4.txt\",sep=' ',index = None, header=None)\n",
    "\n",
    "train5 = train_fast.iloc[:val_size*4,]\n",
    "train5.to_csv(\"train5.txt\",sep=' ',index = None, header=None)\n",
    "val5 = train_fast[val_size*4:]\n",
    "val5.to_csv(\"val5.txt\",sep=' ',index = None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = train[\"label\"].unique()\n",
    "label_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.903121387283237\n",
      "0.9065895953757226\n",
      "0.8991907514450868\n",
      "0.91121387283237\n",
      "0.907326091980587\n"
     ]
    }
   ],
   "source": [
    "def train_pred_fast(k, val):\n",
    "    model = fasttext.train_supervised(input=\"train\"+str(k)+\".txt\", lr = 0.6, epoch = 25)\n",
    "    _,p,r = model.test(\"val\"+str(k)+\".txt\")\n",
    "    print(p)\n",
    "    dictionary = {}\n",
    "    for l in label_list:\n",
    "        dictionary[l] = []\n",
    "    val = val.reset_index()\n",
    "    for index in range(len(val)):\n",
    "        label_array, prednum_array = model.predict(val[\"TextDescription\"][index], k=27)\n",
    "        for i, label in enumerate(label_array):\n",
    "            dictionary[label].append(prednum_array[i])\n",
    "    val_pred_df = pd.DataFrame(dictionary)\n",
    "    return val_pred_df\n",
    "\n",
    "val_pred_df_1 = train_pred_fast(1, val1)\n",
    "val_pred_df_2 = train_pred_fast(2, val2)\n",
    "val_pred_df_3 = train_pred_fast(3, val3)\n",
    "val_pred_df_4 = train_pred_fast(4, val4)\n",
    "val_pred_df_5 = train_pred_fast(5, val5)\n",
    "\n",
    "# the output is the val precision for 5 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking the result for the second stage training\n",
    "\n",
    "train_pred_fast_text = pd.concat([val_pred_df_1, val_pred_df_2, val_pred_df_3, val_pred_df_4, val_pred_df_5])\n",
    "train_pred_fast_text.to_csv(\"train_pred_fast_text.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the full train data \n",
    "\n",
    "model = fasttext.train_supervised(input=\"train_fast.txt\", epoch = 25,lr=0.6)\n",
    "\n",
    "dictionary = {}\n",
    "for l in label_list:\n",
    "    dictionary[l] = []\n",
    "\n",
    "\n",
    "for index in range(len(test)):\n",
    "    label_array, prednum_array = model.predict(test[\"TextDescription\"][index], k=27)\n",
    "    for i, label in enumerate(label_array):\n",
    "        dictionary[label].append(prednum_array[i])\n",
    "\n",
    "# save the result for the second stage training\n",
    "test_df = pd.DataFrame(dictionary)\n",
    "test_df.to_csv(\"test_pred_fast_text.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _FastText in module fasttext.FastText object:\n",
      "\n",
      "class _FastText(builtins.object)\n",
      " |  _FastText(model_path=None, args=None)\n",
      " |  \n",
      " |  This class defines the API to inspect models and should not be used to\n",
      " |  create objects. It will be returned by functions such as load_model or\n",
      " |  train.\n",
      " |  \n",
      " |  In general this API assumes to be given only unicode for Python2 and the\n",
      " |  Python3 equvalent called str for any string-like arguments. All unicode\n",
      " |  strings are then encoded as UTF-8 and fed to the fastText C++ API.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __contains__(self, word)\n",
      " |  \n",
      " |  __getitem__(self, word)\n",
      " |  \n",
      " |  __init__(self, model_path=None, args=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_analogies(self, wordA, wordB, wordC, k=10, on_unicode_error='strict')\n",
      " |  \n",
      " |  get_dimension(self)\n",
      " |      Get the dimension (size) of a lookup vector (hidden layer).\n",
      " |  \n",
      " |  get_input_matrix(self)\n",
      " |      Get a reference to the full input matrix of a Model. This only\n",
      " |      works if the model is not quantized.\n",
      " |  \n",
      " |  get_input_vector(self, ind)\n",
      " |      Given an index, get the corresponding vector of the Input Matrix.\n",
      " |  \n",
      " |  get_label_id(self, label)\n",
      " |      Given a label, get the label id within the dictionary.\n",
      " |      Returns -1 if label is not in the dictionary.\n",
      " |  \n",
      " |  get_labels(self, include_freq=False, on_unicode_error='strict')\n",
      " |      Get the entire list of labels of the dictionary optionally\n",
      " |      including the frequency of the individual labels. Unsupervised\n",
      " |      models use words as labels, which is why get_labels\n",
      " |      will call and return get_words for this type of\n",
      " |      model.\n",
      " |  \n",
      " |  get_line(self, text, on_unicode_error='strict')\n",
      " |      Split a line of text into words and labels. Labels must start with\n",
      " |      the prefix used to create the model (__label__ by default).\n",
      " |  \n",
      " |  get_meter(self, path, k=-1)\n",
      " |  \n",
      " |  get_nearest_neighbors(self, word, k=10, on_unicode_error='strict')\n",
      " |  \n",
      " |  get_output_matrix(self)\n",
      " |      Get a reference to the full output matrix of a Model. This only\n",
      " |      works if the model is not quantized.\n",
      " |  \n",
      " |  get_sentence_vector(self, text)\n",
      " |      Given a string, get a single vector represenation. This function\n",
      " |      assumes to be given a single line of text. We split words on\n",
      " |      whitespace (space, newline, tab, vertical tab) and the control\n",
      " |      characters carriage return, formfeed and the null character.\n",
      " |  \n",
      " |  get_subword_id(self, subword)\n",
      " |      Given a subword, return the index (within input matrix) it hashes to.\n",
      " |  \n",
      " |  get_subwords(self, word, on_unicode_error='strict')\n",
      " |      Given a word, get the subwords and their indicies.\n",
      " |  \n",
      " |  get_word_id(self, word)\n",
      " |      Given a word, get the word id within the dictionary.\n",
      " |      Returns -1 if word is not in the dictionary.\n",
      " |  \n",
      " |  get_word_vector(self, word)\n",
      " |      Get the vector representation of word.\n",
      " |  \n",
      " |  get_words(self, include_freq=False, on_unicode_error='strict')\n",
      " |      Get the entire list of words of the dictionary optionally\n",
      " |      including the frequency of the individual words. This\n",
      " |      does not include any subwords. For that please consult\n",
      " |      the function get_subwords.\n",
      " |  \n",
      " |  is_quantized(self)\n",
      " |  \n",
      " |  predict(self, text, k=1, threshold=0.0, on_unicode_error='strict')\n",
      " |      Given a string, get a list of labels and a list of\n",
      " |      corresponding probabilities. k controls the number\n",
      " |      of returned labels. A choice of 5, will return the 5\n",
      " |      most probable labels. By default this returns only\n",
      " |      the most likely label and probability. threshold filters\n",
      " |      the returned labels by a threshold on probability. A\n",
      " |      choice of 0.5 will return labels with at least 0.5\n",
      " |      probability. k and threshold will be applied together to\n",
      " |      determine the returned labels.\n",
      " |      \n",
      " |      This function assumes to be given\n",
      " |      a single line of text. We split words on whitespace (space,\n",
      " |      newline, tab, vertical tab) and the control characters carriage\n",
      " |      return, formfeed and the null character.\n",
      " |      \n",
      " |      If the model is not supervised, this function will throw a ValueError.\n",
      " |      \n",
      " |      If given a list of strings, it will return a list of results as usually\n",
      " |      received for a single line of text.\n",
      " |  \n",
      " |  quantize(self, input=None, qout=False, cutoff=0, retrain=False, epoch=None, lr=None, thread=None, verbose=None, dsub=2, qnorm=False)\n",
      " |      Quantize the model reducing the size of the model and\n",
      " |      it's memory footprint.\n",
      " |  \n",
      " |  save_model(self, path)\n",
      " |      Save the model to the given path\n",
      " |  \n",
      " |  set_args(self, args=None)\n",
      " |  \n",
      " |  set_matrices(self, input_matrix, output_matrix)\n",
      " |      Set input and output matrices. This function assumes you know what you\n",
      " |      are doing.\n",
      " |  \n",
      " |  test(self, path, k=1, threshold=0.0)\n",
      " |      Evaluate supervised model using file given by path\n",
      " |  \n",
      " |  test_label(self, path, k=1, threshold=0.0)\n",
      " |      Return the precision and recall score for each label.\n",
      " |      \n",
      " |      The returned value is a dictionary, where the key is the label.\n",
      " |      For example:\n",
      " |      f.test_label(...)\n",
      " |      {'__label__italian-cuisine' : {'precision' : 0.7, 'recall' : 0.74}}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  labels\n",
      " |  \n",
      " |  words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.save_model(\"fast_text_model.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
