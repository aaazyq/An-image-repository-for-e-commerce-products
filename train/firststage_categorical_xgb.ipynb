{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xgboost as xgb\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import keras.preprocessing.text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import keras\n",
    "# from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, SpatialDropout1D, Embedding, LSTM\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/uw-cs480-fall20/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/uw-cs480-fall20/test.csv\")\n",
    "\n",
    "data = pd.concat([train, test])\n",
    "\n",
    "data[\"gender_\"] = pd.factorize(data[\"gender\"])[0].astype(np.uint16)/4\n",
    "data[\"baseColour_\"] = pd.factorize(data[\"baseColour\"])[0].astype(np.uint16)/45\n",
    "data[\"season_\"] = pd.factorize(data[\"season\"])[0].astype(np.uint16)/3\n",
    "data[\"usage_\"] = pd.factorize(data[\"usage\"])[0].astype(np.uint16)/6\n",
    "\n",
    "data.head()\n",
    "\n",
    "train_categorical_df = pd.DataFrame(data[:len(train)], columns = ['gender_','baseColour_','season_','usage_'])\n",
    "test_categorical_df = pd.DataFrame(data[len(train):], columns = ['gender_','baseColour_','season_','usage_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = train[\"category\"].unique()\n",
    "category_list.sort()\n",
    "category_mapping = {label:idx for idx,label in enumerate(category_list)}\n",
    "num_mapping = {idx:label for idx,label in enumerate(category_list)}\n",
    "\n",
    "train_total_Y = train['category'][:len(train)].map(category_mapping)\n",
    "\n",
    "train_Y = train['category'][:20000].map(category_mapping)\n",
    "eval_Y = train['category'][20000:len(train)].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_train = xgb.DMatrix(xgb_train_X, label=train_Y)\n",
    "# xg_eval = xgb.DMatrix(xgb_eval_X, label=eval_Y)  \n",
    "\n",
    "xg_train = xgb.DMatrix(train_categorical_df[:20000], label=train_Y)\n",
    "xg_eval = xgb.DMatrix(train_categorical_df[20000:], label=eval_Y) \n",
    "\n",
    "train_categorical_df\n",
    "\n",
    "\n",
    "# setup parameters for xgboost  \n",
    "param = {}  \n",
    "# use softmax multi-class classification  \n",
    "param['objective'] = 'multi:softmax'  \n",
    "# scale weight of positive examples  \n",
    "param['eta'] = 0.1  \n",
    "param['max_depth'] = 3  \n",
    "# param['silent'] = 1  \n",
    "param['nthread'] = 4  \n",
    "param['num_class'] = 27  \n",
    "  \n",
    "# watchlist = [(xg_train,'train'), (xg_eval, 'eval') ]  \n",
    "# num_round = 200  \n",
    "# bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "\n",
    "# # get prediction  \n",
    "# pred = bst.predict(xg_eval); \n",
    "\n",
    "# print ('predicting, classification error=%f' % (1- sum(eval_Y == pred)/len(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.544560540872772\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(nthread=4, max_depth=3, silent=0, \n",
    "                                   objective='multi:softmax', n_estimators=200)\n",
    "xgb_classifier = xgb_classifier.fit(train_categorical_df[:20000], train_Y)\n",
    "\n",
    "predictions = xgb_classifier.predict(train_categorical_df[20000:])\n",
    "acc = sum(predictions == eval_Y) /len(eval_Y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1627, 27)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pred = xgb_classifier.predict_proba(train_categorical_df[20000:])\n",
    "eval_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17300,) (4327,)\n"
     ]
    }
   ],
   "source": [
    "val_size = int(len(train)/5)\n",
    "\n",
    "X_train1 = train_categorical_df[val_size:]\n",
    "X_val1 = train_categorical_df[:val_size]\n",
    "\n",
    "X_train2 = pd.concat([train_categorical_df.iloc[:val_size,], train_categorical_df.iloc[val_size*2:]])\n",
    "X_val2 = train_categorical_df[val_size:val_size*2]\n",
    "\n",
    "X_train3 = pd.concat([train_categorical_df.iloc[:val_size*2,], train_categorical_df.iloc[val_size*3:]])\n",
    "X_val3 = train_categorical_df[val_size*2:val_size*3]\n",
    "\n",
    "X_train4 = pd.concat([train_categorical_df.iloc[:val_size*3,], train_categorical_df.iloc[val_size*4:]])\n",
    "X_val4 = train_categorical_df[val_size*3:val_size*4]\n",
    "\n",
    "X_train5 = train_categorical_df.iloc[:val_size*4,]\n",
    "X_val5 = train_categorical_df[val_size*4:]\n",
    "\n",
    "Y_train1 = train_total_Y[val_size:]\n",
    "Y_val1 = train_total_Y[:val_size]\n",
    "\n",
    "Y_train2 = pd.concat([train_total_Y.iloc[:val_size,], train_total_Y.iloc[val_size*2:]])\n",
    "Y_val2 = train_total_Y[val_size:val_size*2]\n",
    "\n",
    "Y_train3 = pd.concat([train_total_Y.iloc[:val_size*2,], train_total_Y.iloc[val_size*3:]])\n",
    "Y_val3 = train_total_Y[val_size*2:val_size*3]\n",
    "\n",
    "Y_train4 = pd.concat([train_total_Y.iloc[:val_size*3,], train_total_Y.iloc[val_size*4:]])\n",
    "Y_val4 = train_total_Y[val_size*3:val_size*4]\n",
    "\n",
    "Y_train5 = train_total_Y.iloc[:val_size*4,]\n",
    "Y_val5 = train_total_Y[val_size*4:]\n",
    "\n",
    "print(Y_train5.shape,Y_val5.shape)\n",
    "# print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_train_second_stage(X_train, Y_train, X_val, Y_val):\n",
    "\n",
    "    xgb_classifier = xgb.XGBClassifier(nthread=4, max_depth=3, silent=0, \n",
    "                                       objective='multi:softmax', n_estimators=200)\n",
    "    xgb_classifier = xgb_classifier.fit(X_train, Y_train)\n",
    "\n",
    "    predictions = xgb_classifier.predict(X_val)\n",
    "    acc = sum(predictions == Y_val) /len(Y_val)\n",
    "    print(acc)\n",
    "    eval_pred = xgb_classifier.predict_proba(X_val)\n",
    "    return xgb_classifier, eval_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5320231213872832\n",
      "0.5387283236994219\n",
      "0.5452023121387283\n",
      "0.5479768786127167\n",
      "0.5474924890224174\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier1, eval_pred_second1 = xgb_train_second_stage(X_train1, Y_train1, X_val1, Y_val1)\n",
    "xgb_classifier2, eval_pred_second2 = xgb_train_second_stage(X_train2, Y_train2, X_val2, Y_val2)\n",
    "xgb_classifier3, eval_pred_second3 = xgb_train_second_stage(X_train3, Y_train3, X_val3, Y_val3)\n",
    "xgb_classifier4, eval_pred_second4 = xgb_train_second_stage(X_train4, Y_train4, X_val4, Y_val4)\n",
    "xgb_classifier5, eval_pred_second5 = xgb_train_second_stage(X_train5, Y_train5, X_val5, Y_val5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xgb_first_pred = np.concatenate([eval_pred_second1, eval_pred_second2, eval_pred_second3, eval_pred_second4,eval_pred_second5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5359537572254335\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier_second_stage, eval_pred = xgb_train_second_stage(train_categorical_df, train_total_Y, X_val1, Y_val1)\n",
    "test_xgb_first_pred = xgb_classifier_second_stage.predict_proba(test_categorical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_xgb_first_pred).to_csv(\"category_xgb_train.csv\", index=False)\n",
    "pd.DataFrame(test_xgb_first_pred).to_csv(\"category_xgb_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
